---
title: "starschemar: Obtaining Star Schemas from Flat Tables"
author: "Jose Samos (jsamos@ugr.es)"
date: "2020-07-24"
output: rmarkdown::html_vignette
bibliography: bibliography.bib
vignette: >
  %\VignetteIndexEntry{starschemar: Obtaining Star Schemas from Flat Tables}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, echo = FALSE}
library(starschemar)
```

# Introduction

The *multidimensional data model* was defined in the 1990s with the aim of supporting data analysis. Data in multidimensional systems is obtained from operational systems and is transformed to adapt it to the new structure.

Transformations can be carried out using professional ETL (extract, transform and load) tools. Recently, tools aimed at end users have emerged, which are also aimed at performing transformation operations. All these tools are very useful to carry out the transformation process, they provide a development environment to define the transformation operations in a general way.

Frequently, the operations to be performed aim to transform a flat table (with data that comes from operational systems) into a star schema (which implements a multidimensional system). With the tools mentioned above, this transformation can be carried out, but it requires a lot of work. I am not aware of any tools with operations designed to specifically support this transformation process. 

This is the main objective of `starschemar` package: Define **transformations that allow obtaining star schemas from flat tables** easily. In addition, it includes basic data cleaning operations and incremental data refresh operations, adapted to this context.

The rest of this document is structured as follows: First, basic concepts of dimensional modelling and star schemas are summarized. The following is an illustrative example of how the package works. Then, the operations available in the package are briefly presented. Finally, the document ends with conclusions and bibliography.

# Dimensional modelling and star schemas

The content of this section is a summary based mainly on @adamson2010star and @kimball2013data. It is intended to present the fundamental concepts of the area that are relevant to understand the functionality, naming and use of the `starschemar` package.

## Dimensional modelling

Dimensional modelling aims to obtain simple data models. Simplicity is sought for two reasons: so that decision-makers can easily understand the data, and also so that they can be easily queried.

In dimensional modelling, the analysis of a business process is performed *modelling how it is measured*. The measures are called *facts*, and the descriptors of the context of the facts are *dimensions*. Facts are numerical data, and decision makers want to see them at various levels of detail, defined by dimensions.

Not all numerical data is a fact (some tools consider it that way). In dimensional modelling the designer has to differentiate between facts and dimensions. Some criteria are considered to distinguish between them, for example:

- If it can be defined at different levels of detail then it is a fact.
- If it is quantitative and takes continuous values, then it is a fact.
- If it provides context then it is a dimension.

Sometimes there are no measures associated with the business process, it is simply recorded that the combination of dimensions has occurred. This situation is often called *factless facts*, @jensen2010multi prefer to call it *measureless facts*. In any case, including when no other measures are available, a measure can be considered that represents the number of times the combination of dimension values occurs.

### Dimensions and dimension attributes

Attributes considered by the designer as dimensions can be grouped taking into account the natural affinities between them. In particular, they can be grouped as they describe the "who, what, where, when, how and why" associated with the modelled business process. Two attributes share a natural affinity when they are only related in one context. When their relationships are determined by transactions or activities, they can occur in multiple contexts, if this occurs, they must be located in different dimensions.

In this way, a *dimension* is made up of a set of naturally related *dimension attributes* that describe the context of facts. Dimensions are used for two purposes: fact *selection* and fact *grouping* with the desired level of detail.

Additionally, in the dimensions *hierarchies* with *levels* and *descriptors* can be defined. More details can be found at @jensen2010multi. These concepts are not used in the current version of the package.

### Facts and measures

A fact has a *granularity*, which is determined by the attributes of the dimensions that are considered at each moment. Thus, a measure in a fact has two components, the *numerical property* of the fact and an *formula*, frequently the SUM aggregation function, that allows combining several values of this measure to obtain a new value of the same measure with a coarser granularity [@jensen2010multi]. 

According to their behaviour to obtain a coarser granularity, three types of measures are distinguished: additive, semi-additive and non-additive. For *additive measures*, SUM is always a valid formula that maintains the meaning of the measure when the granularity changes. For *semi-additive measures*, there is no point in using SUM when changing the level of detail in any of the dimensions because the meaning of the measure changes, this frequently occurs in dimensions that represents time and measures representing inventory level. For *non-additive measures*, values cannot be combined across any dimension using SUM because the result obtained has a different meaning from the original measure (generally occurs with ratios, percentages or unit amounts such as unit cost or unit price). 

The most useful measures are additive. If we have non-additive measures, they can generally be redefined from other additive measures.


## Star schemas

Dimensional models implemented in RDBMS (Relational Database Management Systems) using a table for each dimension are called *star schemas* because of their resemblance to a star-like structure: A *fact table* in the centre and *dimension tables* around it. Thus, dimension attributes are columns of the respective dimension tables, and measures are columns of the fact table.

Other possible implementations on RDBMS normalize dimensions and are known as *snowflake schema*. More details can be found at @jensen2010multi. This is not considered in this package.

### Dimension tables

Dimension tables contain the context associated with business process measures. Although they can contain any type of data, numerical data is generally not used for dimension attributes because some query tools consider any numeric data as a measure.

Dimension attributes with NULL value are a source of problems when querying since DBMS and query tools sometimes handle them inconsistently, the result depends on the product. It is recommended to avoid the use of NULL and replace them with a descriptive text. In the case of dates, it is recommended to replace the NULL values with an arbitrary date in the very far future.

#### Surrogate keys

A dimension table contains dimension attributes and also a *surrogate key* column. This column is a unique identifier that has no intrinsic meaning: It is generally an integer and is the primary key for the dimension table. In @adamson2010star surrogate keys are easily identifiable by the suffix "_key" in the column name (and this criterion has also been applied in `starschemar` package).

Dimension tables also contain key columns that uniquely identify associated entities in an operational system. The separation of surrogate keys and natural keys allows the star schema to store changes in dimensions. Therefore, the use of surrogate keys in dimensions is a solution to the SCD (slowly changing dimensions) problem. This problem is not specifically addressed in this version of this package.

#### Special dimensions

In some cases, for the sake of simplicity, it is helpful to create a table that contains dimension attributes that have no natural affinities to each other, generally these are low-cardinality flags and indicators. The result is what is known as a *junk dimension*. They do not require any special support, only the designer's will to define them.

Sometimes some dimension attributes are left in the fact table, usually transaction identifiers. It is considered as the primary key of a dimension that does not have an associated table, for this reason it is known as a *degenerate dimension*. Degenerate dimensions are not allowed in this package.

A single dimension can be referenced multiple times in a fact table, with each reference linked to a different logical role for each dimension. These separate dimension views, with unique attribute column names, are called *role dimensions* and the common dimension is called a *role-playing dimension*.

Associated with multiple star schemas we have the *conformed dimensions* that are presented in section [Conformed dimensions].

### Fact table

At the centre of a star schema is the fact table. In addition to containing measures, the fact table includes foreign keys that refer to each of the surrogate keys in the dimension tables.

#### Primary key

A subset of foreign keys, along with possibly degenerate dimensions, is considered to form the primary key of the fact table. 

In `starschemar` package, since degenerate dimensions are not allowed, the primary key is made up of a subset of foreign keys. 

#### Grain

The subset of dimensions that forms the primary key defines the level of detail stored in the fact table, which is known as the fact table's *grain*. In the design process, it is very important for the designer to clearly define the grain of the fact table (it is usually defined by listing the dimensions whose surrogate keys form its primary key): it is a way to ensure that all the facts are stored at the same level of detail. 

At the finest grain, a row in the fact table corresponds to the measures of an event and vice versa, it is not influenced by the possible reports that may be obtained. When two facts have different grains, they should be set on different fact tables.


### Multiple fact tables

It is frequent the need to have several fact tables for various reasons: 

- We find measurements with different grain. 

- There are measures that do not occur simultaneously, for example, when one occurs, we have no value for others and vice versa. 

In reality it is about different business processes, each one has to have its own fact table but they have dimensions in common. This is known as a [*fact constellation*](https://www.geeksforgeeks.org/fact-constellation-in-data-warehouse-modelling/) which corresponds to the Kimball *enterprise data warehouse bus architecture*.

### Conformed dimensions

When star schemas share a set of common dimensions, these dimensions are called *conformed dimensions*.

There are several possibilities to have conformed dimensions, the most obvious form is that the dimension tables share *structure* and *content*, that is, they are identical dimensions. This is the one considered in this version of the `starschemar` package.

## Additional operations

### Cleaning and conforming data

When data is loaded into a star schema, errors or inconsistencies can be discovered in some of them. In some cases, it is best to make corrections at the source of the data, in operational systems. Sometimes this is not possible and there is no other option but to modify the data before loading it into the star schema or even when it is already loaded.

Inconsistencies are often found in dimensions, when dimensions are integrated into one, for example to generate a role-playing dimension or conformed dimensions. Support for modifying dimension data is provided in the package.

### Incremental refresh

When a star schema is built, an initial load is performed with all available data from a moment in time onwards.

Operational systems continue to operate and produce data. If we want to incorporate these data into the star schema, we have two possibilities: 

- Carry out a new load with all the data available at that time.

- Perform an incremental refresh with only the new data.

In order to carry out this second option, the CDC (change data capture) system allows to exclusively obtain the new data produced.

In this package, it has been considered that we can obtain the new data, possibly mixed with updates to data already incorporated into the star schema, in order to carry out an incremental refresh of star schemas with them.

# An illustrative example


## Starting data sets
To illustrate how the package works we will use a small part of the [Deaths in 122 U.S. cities - 1962-2016. 122 Cities Mortality Reporting System](https://catalog.data.gov/dataset/deaths-in-122-u-s-cities-1962-2016-122-cities-mortality-reporting-system) data set[^1]. Specifically, only the data for the first 11 weeks of 1962 are considered.

[^1]: I know this data set thanks to Alberto J. Duran, student of *Multidimensional Systems* during the 2019-2020 academic year, a subject I teach at the University of Granada (Spain), for a work he developed based on it, tutored by me.

```{r, results = "asis", echo = FALSE}
pander::pandoc.table(head(mrs, 12), split.table = Inf)
```

In the table above, the first rows of the original data are shown. For each week and city, mortality figures by age group and cause, considered separately, are included (i.e., the combination of age group and cause is not included). In the cause, only a distinction is made between pneumonia or influenza and others. 

It can be seen that there is only one measure, *deaths*, defined at two different granularities: *week-city-cause* (data in columns "Pneumonia and Influenza Deaths" and "All Deaths") and *week-city-age bracket* (data from the 5 columns on the right). This means that we will need **two fact tables** to include all the data in star schemas.

As the data is partially in the form of a pivot table, from these data two tables have been generated[^2], one for each granularity. Additionally, the following operations have been carried out:

- To show the incremental refresh, the data has been selected: On the one hand, the first 9 weeks were considered, and on the other, each of the following weeks separately. 

- To show the possibilities of data modification operations to correct errors, some data has been modified to generate missing data or errors.

[^2]: The transformation has been carried out with [`tidyverse`](https://CRAN.R-project.org/package=tidyverse) and [`flattabler`](https://CRAN.R-project.org/package=flattabler) packages.

```{r, results = "asis", echo = FALSE}
pander::pandoc.table(head(mrs_age[,-c(1:6)]), split.table = Inf)
```

In the table above, the first rows of the flat table that contains the data according to the age bracket are shown.

The following table shows the first 18 rows of the flat table containing data based on cause of death. The calculated column *Other Deaths* has been added. Here you can see some missing data (columns *Year* and *WEEK*), errors (value "Bridgepor" in column *City*) and how there are only data from the first 9 weeks.

```{r, results = "asis", echo = FALSE}
pander::pandoc.table(head(mrs_cause[,-c(1:6)], 18), split.table = Inf)
```

To have more layout possibilities to display, new columns with dates have been generated. Next, in both tables, the new columns related to the date that have been added can be seen.

```{r, results = "asis", echo = FALSE}
pander::pandoc.table(head(mrs_age), split.table = Inf)
```

```{r, results = "asis", echo = FALSE}
pander::pandoc.table(head(mrs_cause), split.table = Inf)
```

These are the flat tables that will be considered as a starting point to obtain star schemas from them in this example. They are available in the package: `mrs_age` and `mrs_cause` respectively.

## Dimensional modelling

For each flat table, the goal is to define the attributes that correspond to facts and those that are dimensions. For facts, measures and their aggregation functions have to be defined. For dimensions, attributes with natural affinity must be grouped. Each attribute can only appear once in the definition.

### Data according to age range

To avoid having to write the name of the attributes of the table, with the following function we can have them in the form of a string. Thus, we can copy and paste each name as needed.

```{r}
dput(colnames(mrs_age))
```

The definition of the dimensional model for the data considered is shown below.

```{r}
library(tidyr)
library(starschemar)

dm_mrs_age <- dimensional_model() %>%
  define_fact(
    name = "mrs_age",
    measures = c(
      "Deaths"
    ),
    agg_functions = c(
      "SUM"
    ),
    nrow_agg = "nrow_agg"
  ) %>%
  define_dimension(
    name = "when",
    attributes = c(
      "Week Ending Date",
      "WEEK",
      "Year"
    )
  ) %>%
  define_dimension(
    name = "when_available",
    attributes = c(
      "Data Availability Date",
      "Data Availability Week",
      "Data Availability Year"
    )
  ) %>%
  define_dimension(
    name = "where",
    attributes = c(
      "REGION",
      "State",
      "City"
    )
  ) %>%
  define_dimension(
    name = "who",
    attributes = c(
      "Age Range"
    )
  )
```

In this case, all the elements have been explicitly defined, including aggregation functions and the name of an additional measure representing the number of rows aggregated, which is always included. Only data from two of the three possible time-related dimensions have been considered.

### Data according to cause

In the case of data according to cause of death, the definition of the model is shown below.

```{r}
dm_mrs_cause <- dimensional_model() %>%
  define_fact(
    name = "mrs_cause",
    measures = c(
      "Pneumonia and Influenza Deaths",
      "Other Deaths"
    ),
  ) %>%
  define_dimension(
    name = "when",
    attributes = c(
      "Week Ending Date",
      "WEEK",
      "Year"
    )
  ) %>%
  define_dimension(
    name = "when_received",
    attributes = c(
      "Reception Date",
      "Reception Week",
      "Reception Year"
    )
  ) %>%
  define_dimension(
    name = "when_available",
    attributes = c(
      "Data Availability Date",
      "Data Availability Week",
      "Data Availability Year"
    )
  ) %>%
  define_dimension(
    name = "where",
    attributes = c(
      "REGION",
      "State",
      "City"
    )
  )
```

If no aggregation function is indicated, by default, SUM is considered. Although not explicitly stated, it also includes by default the measure relative to the number of rows aggregated. In this case, the three dimensions related to the date have been defined.


## Star schema and constellation definition

### Star schema definition

To define a star schema, we need a flat table and a dimensional model defined from it. To define a star schema, we need a flat table and a dimensional model defined from it. Once defined, we can apply format modification operations to it.

#### Data according to age range

The basic definition operation of a star schema is shown below[^3].

[^3]: `SaveRDS` and `readRDS` functions can be used to save and retrieve star schemas or any other defined data structure.

```{r}
st_mrs_age <- star_schema(mrs_age, dm_mrs_age)
```

The first rows of the obtained dimension and fact tables are shown below.

```{r, results = "asis", echo = FALSE}
pander::pandoc.table(head(st_mrs_age$dimension$when), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$dimension$when_available), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$dimension$where), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$dimension$who), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$fact$mrs_age), split.table = Inf)
```

The data from the original flat table has been structured in the form of dimension tables and fact tables. Data in the columns of the original table included in the dimensions is not repeated. A surrogate key has been added to each of the dimension tables that are foreign keys in the fact table.

Next, we will apply format modification operations to the original structure obtained.

```{r}
st_mrs_age <- st_mrs_age %>%
  role_playing_dimension(
    dim_names = c("when", "when_available"),
    name = "When Common",
    attributes = c("date", "week", "year")
  ) %>%
  snake_case() %>%
  character_dimensions(NA_replacement_value = "Unknown",
                       length_integers = list(week = 2))
```

First, a role playing dimension has been defined based on the dimensions related to dates. Then, to work with databases, the names have been adapted to the snake case criterion. Finally, the data type of the attributes of the dimensions has been transformed so that all columns except the date columns are of the character data type, in the case of numerical data, it is allowed to indicate the length of the field to fill with leading zeros, and undefined values have been replaced by the indicated value.

The first rows of the new dimension and fact tables are shown below.

```{r, results = "asis", echo = FALSE}
pander::pandoc.table(head(st_mrs_age$dimension$when), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$dimension$when_available), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$dimension$where), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$dimension$who), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$dimension$when_common), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$fact$mrs_age), split.table = Inf)
```

In the result, it can be seen that the dimensions related to date are now role dimensions and do not have their own data, a role playing dimension has been generated with the integrated data. The fact table continues to refer to role dimensions, the value of foreign keys has been adapted to the possible new values of the surrogate keys. Additionally it can be seen that the *week* field now has length 2 and has 0 on the left (this is useful to order numbers in text format).


#### Data according to cause

We are going to define the star schema and apply similar transformations to the other flat table. The transformations can be applied in any order. 

```{r}
st_mrs_cause <- star_schema(mrs_cause, dm_mrs_cause) %>%
  snake_case() %>%
  character_dimensions(
    NA_replacement_value = "Unknown",
    length_integers = list(
      week = 2,
      data_availability_week = 2,
      reception_week = 2
    )
  ) %>%
  role_playing_dimension(
    dim_names = c("when", "when_received", "when_available"),
    name = "when_common",
    attributes = c("date", "week", "year")
  )
```

In this case, since the role playing dimension definition is the last transformation defined, the format of the *week* column had to be defined in the three date dimensions to obtain an equivalent result. The result obtained is shown below.

```{r, results = "asis", echo = FALSE}
pander::pandoc.table(head(st_mrs_cause$dimension$when), split.table = Inf)
pander::pandoc.table(head(st_mrs_cause$dimension$when_received), split.table = Inf)
pander::pandoc.table(head(st_mrs_cause$dimension$when_available), split.table = Inf)
pander::pandoc.table(head(st_mrs_cause$dimension$where), split.table = Inf)
pander::pandoc.table(head(st_mrs_cause$dimension$when_common), split.table = Inf)
pander::pandoc.table(head(st_mrs_cause$fact$mrs_cause), split.table = Inf)
```

In this case we have three role dimensions defined on a role playing dimension.

### Constellation definition

A constellation is defined from a list of star schemas, as shown below. 

```{r}
ct_mrs <- constellation(list(st_mrs_age, st_mrs_cause), name = "mrs")
```

All dimensions of the same name in star schemas must be compatible in structure and type of columns, and are defined as conformed dimensions. The conformed dimensions share all the instances of the original dimensions, this implies possible modifications in the surrogate keys that are transmitted to foreign keys of the component fact tables.

The tables of the obtained conformed dimensions are shown below.

```{r, results = "asis", echo = FALSE}
pander::pandoc.table(head(ct_mrs$dimension$when), split.table = Inf)
pander::pandoc.table(head(ct_mrs$dimension$when_available), split.table = Inf)
pander::pandoc.table(head(ct_mrs$dimension$where), split.table = Inf)
```

It can be seen that the conformed dimensions are considered regardless of the type of dimension in the star schema. Definition of conformed dimensions does not imply any change in the definition of dimensions in star schemas: Role and role playing dimensions remain the same, only their rows may have changed.


## Cleaning and conforming data

We can perform data cleaning on star schema dimensions. 

### Definition of updates

Using the following code, first of all, we get the names of the dimensions of a star schema, then, we get them by their name (using `utils::View` function we can see the rows). If there are several role dimensions, it is enough to consult one of them, updates defined on it will be propagated to the rest.

```{r}
dim_names <- st_mrs_age %>%
    get_dimension_names()

where <- st_mrs_age %>%
  get_dimension("where")

# View(where)

when <- st_mrs_age %>%
  get_dimension("when")

# View(when)
# when[when$when_key %in% c(36, 37, 73), ]

who <- st_mrs_age %>%
  get_dimension("who")

# View(who)
```

Below is a selection of rows involved in update operations that are referred by their surrogate key.

```{r, results = "asis", echo = FALSE}
pander::pandoc.table(when[when$when_key %in% c(36, 37, 73), ], split.table = Inf)
```

Updates are defined on dimensions. Various update definition functions are available, as shown below.

```{r}
updates_st_mrs_age <- record_update_set() %>%
  update_selection_general(
    dimension = where,
    columns_old = c("state", "city"),
    old_values = c("CT", "Bridgepor"),
    columns_new = c("city"),
    new_values = c("Bridgeport")
  ) %>%
  match_records(dimension = when,
                old = 37,
                new = 36) %>%
  update_record(
    dimension = when,
    old = 73,
    values = c("1962-02-17", "07", "1962")
  ) %>%
  update_selection(
    dimension = who,
    columns = c("age_range"),
    old_values = c("<1 year"),
    new_values = c("1: <1 year")
  ) %>%
  update_selection(
    dimension = who,
    columns = c("age_range"),
    old_values = c("1-24 years"),
    new_values = c("2: 1-24 years")
  ) %>%
  update_selection(
    dimension = who,
    columns = c("age_range"),
    old_values = c("25-44 years"),
    new_values = c("3: 25-44 years")
  ) %>%
  update_selection(
    dimension = who,
    columns = c("age_range"),
    old_values = c("45-64 years"),
    new_values = c("4: 45-64 years")
  ) %>%
  update_selection(
    dimension = who,
    columns = c("age_range"),
    old_values = c("65+ years"),
    new_values = c("5: 65+ years")
  )
```

Although in some of the functions the dimension surrogate key is referred to, updates only consider the values of the rest of the columns of the corresponding dimension. In this way, it is achieved that updates can be applied to equivalent dimensions of other star schemas, where the values of the surrogate key do not necessarily coincide with those of the dimension where updates were originally defined.

### Updates application

Once updates are defined, they can be applied on the star schema from which they have been defined, as shown below. 

```{r}
st_mrs_age <- st_mrs_age %>%
  modify_dimension_records(updates_st_mrs_age)
```

The result obtained for the first star schema is shown below.

```{r, results = "asis", echo = FALSE}
pander::pandoc.table(head(st_mrs_age$dimension$when), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$dimension$when_available), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$dimension$where), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$dimension$who), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$dimension$when_common), split.table = Inf)
pander::pandoc.table(head(st_mrs_age$fact$mrs_age), split.table = Inf)
```

It can be seen that the row with the value "Bridgepor" in the *city* column has disappeared: it has been merged with the row with the correct value. This update has also been transmitted to the fact table. Although it is not seen in the tables, the same has happened with the dates that have been unified by the update.

The same updates can also be applied to other star schemas with dimensions in common with the original star schema, or to the shaped dimensions of a constellation, as shown below.

```{r}
st_mrs_cause <- st_mrs_cause %>%
  modify_dimension_records(updates_st_mrs_age)

ct_mrs <- ct_mrs %>%
  modify_conformed_dimension_records(updates_st_mrs_age)
```

In the latter case, the ideal procedure is to apply particular updates to star schemas before forming the constellation and define custom updates for conformed dimensions, this is just an example. Functions are also available to obtain the names of conformed dimensions and the dimensions themselves. Updates on these dimensions are propagated to the corresponding dimensions of the component star schemas.


## Incremental refresh

Once we have star schemas built with the data available at the moment, we may obtain additional data, with the same structure as the initial data but from a later time. Sometimes the new data also includes data from previous periods to operate on them.

Under these conditions, suppose we get the data sets `mrs_age_w10`, `mrs_age_w11`, `mrs_cause_w10`, and `mrs_cause_w11`, for weeks 10 and 11 (data in star schemas runs through week 9). In all cases, some data from previous periods are included.

To perform an incremental refresh of a star schema, we must have the new data in the same star schema format. Additionally, if we have done data cleaning, it is likely that we will have to correct part of the corrected errors again over the new data. For this reason, it is best to package all the transformations carried out on the original data in function form so that they can be easily applied to new data.

### Data according to age range

Below you can see the function that groups the transformations defined for the data according to the age range.
```{r}
mrs_age_definition <- function(ft, dm, updates) {
  star_schema(ft, dm) %>%
    role_playing_dimension(
      dim_names = c("when", "when_available"),
      name = "When Common",
      attributes = c("date", "week", "year")
    ) %>%
    snake_case() %>%
    character_dimensions(NA_replacement_value = "Unknown",
                         length_integers = list(week = 2)) %>%
    modify_dimension_records(updates)
}
```

We apply this function to new data sets, as shown below.

```{r}
st_mrs_age_w10 <-
  mrs_age_definition(mrs_age_w10, dm_mrs_age, updates_st_mrs_age)

st_mrs_age_w11 <-
  mrs_age_definition(mrs_age_w11, dm_mrs_age, updates_st_mrs_age)
```

Once we have the data in the same format, we can apply the incremental refresh to the original star schema, as follows.

```{r}
st_mrs_age <- st_mrs_age %>%
  incremental_refresh_star_schema(st_mrs_age_w10, existing = "replace") %>%
  incremental_refresh_star_schema(st_mrs_age_w11, existing = "replace")
```

In this case, it has been assumed that if data from previous periods appears among the new data, the new data has to replace the previous data (value "replace" in `existing` parameter).

If the star schema has been integrated into a constellation, the incremental refresh can be performed on it, as follows.

```{r}
ct_mrs <- ct_mrs %>%
  incremental_refresh_constellation(st_mrs_age_w10, existing = "replace") %>%
  incremental_refresh_constellation(st_mrs_age_w11, existing = "replace")
```

In this case, the corresponding star schema, the conformed dimensions and all the star schemas that share them are updated.

### Data according to cause

Similar to how it has been done for age data, it can be done for cause data, as shown below.

```{r}
mrs_cause_definition <- function(ft, dm, updates) {
  star_schema(ft, dm) %>%
    snake_case() %>%
    character_dimensions(
      NA_replacement_value = "Unknown",
      length_integers = list(
        week = 2,
        data_availability_week = 2,
        reception_week = 2
      )
    ) %>%
    role_playing_dimension(
      dim_names = c("when", "when_received", "when_available"),
      name = "when_common",
      attributes = c("date", "week", "year")
    ) %>%
    modify_dimension_records(updates)
}

st_mrs_cause_w10 <-
  mrs_cause_definition(mrs_cause_w10, dm_mrs_cause, updates_st_mrs_age)

st_mrs_cause_w11 <-
  mrs_cause_definition(mrs_cause_w11, dm_mrs_cause, updates_st_mrs_age)

st_mrs_cause <- st_mrs_cause %>%
  incremental_refresh_star_schema(st_mrs_cause_w10, existing = "group") %>%
  incremental_refresh_star_schema(st_mrs_cause_w11, existing = "group")

ct_mrs <- ct_mrs %>%
  incremental_refresh_constellation(st_mrs_cause_w10, existing = "group") %>%
  incremental_refresh_constellation(st_mrs_cause_w11, existing = "group")
```

In this case, the previously existing data is treated differently than it was in the previous case, now what is done is grouping it using the aggregation functions, assuming it is additional data that has not been entered before (value "group" in `existing` parameter).


## Exporting results

Once we have made the necessary definitions and transformations, we can export the data to work in a database or with a query tool.

Instead of exporting data in the specific format of a particular tool, it is exported as `tibble`-based structures that can be easily handled.

### Star schema

Various export possibilities are offered. Specifically, for a star schema one of them is to export the data as a flat table. The main difference from the initial data is that we have cleaned and conformed it. This operation is offered for completeness. To work only with flat tables, this package is not suitable.

To work with databases, it is useful to be able to export a star schema as a list of `tibble` with dimension and fact tables, as shown below. 

```{r}
tl <- st_mrs_age %>%
  star_schema_as_tibble_list()
```

Optionally, the export function allows the role playing dimensions to be included.

### Constellation

To export constellation data, as well as a `tibble` list, the `multistar` format may be interesting, where you have a list of `tibble` for fact tables and another for dimension tables.

```{r}
ms <- ct_mrs %>%
  constellation_as_multistar()
```


# Transformation operations

Package `starschemar` offers operations to transform flat tables into star schemas.

1. From a flat table, we define a dimensional model classifying its attributes as facts or dimensions (*dimensional modelling*).

1. From a flat table and a dimensional model we obtain a star schema that we can transform; from various star schemas we can define a constellation (*star schema and constellation definition*).

1. Dimensions contain rows without duplicates, we can apply operations to perform data cleaning and to conform them (*cleaning and conforming data*).

1. When new data is obtained, it is necessary to refresh the existing data with them by means of incremental refresh operations (*incremental refresh*).

1. Finally, the results obtained can be exported to be consulted with other tools (*exporting results*).


## Dimensional modelling

Starting from a flat table, a dimensional model is defined specifying the attributes that make up each of the dimensions and the measurements in the facts. The result is a `dimensional_model` object. It is carried out through the following  functions:

- `dimensional_model()`: An empty `dimensional_model` object is created in which definition of facts and dimensions can be added. Example:
```{r}
dm <- dimensional_model()
```

- `define_dimension()`: To define a dimension in a `dimensional_model` object, we have to define its name and the set of attributes that make it up. Example:
```{r}
dm <- dimensional_model() %>%
  define_dimension(name = "When",
                   attributes = c("Week Ending Date",
                                  "WEEK",
                                  "Year"))
```


- `define_fact()`: To define facts in a `dimensional_model` object, the essential data is a name and a set of measurements that can be empty (does not have explicit measurements). Associated with each measurement, an aggregation function is required, which by default is SUM. Examples:
```{r}
dm <- dimensional_model() %>%
  define_fact(
    name = "mrs_age",
    measures = c("Deaths"),
    agg_functions = c("SUM"),
    nrow_agg = "nrow_agg"
  )

dm <- dimensional_model() %>%
  define_fact(name = "Factless fact")
```


## Star schema and constellation definition

A dimensional model is implemented using a star schema. We can have several related star schemas through common dimensions that together form a fact constellation.

### Star schema definition

A star schema is defined from a flat table and a dimensional model definition. Once defined, a star schema can be transformed by defining role playing dimensions, changing the writing style of element names or the type of dimension attributes. These operations are carried out through the following functions:

- `star_schema()`: Creates a `star_schema` object from a flat table (implemented by a `tibble`) and a `dimensional_model` object. Example:
```{r}
st <- star_schema(mrs_age, dm_mrs_age)
```

- `role_playing_dimension()`: Given a list of `star_schema` dimension names, all with the same structure, a role playing dimension with the indicated name and attributes is generated. The original dimensions become role dimensions defined from the new role playing dimension. Example:
```{r}
st <- star_schema(mrs_age, dm_mrs_age) %>%
  role_playing_dimension(
    dim_names = c("when", "when_available"),
    name = "When Common",
    attributes = c("Date", "Week", "Year")
  )
```

- `snake_case()`: Transform fact, dimension, measurement, and attribute names according to the snake case style. Example:
```{r}
st <- star_schema(mrs_age, dm_mrs_age) %>%
  snake_case()
```

- `character_dimensions()`: Transforms numeric type attributes of dimensions into character type. In a `star_schema` numerical data are measurements that are situated in the facts. Numerical data in dimensions are usually codes, day, week, month or year numbers. There are tools that consider any numerical data to be a measurement, for this reason it is appropriate to transform the numerical data of dimensions into character data. It also allows indicating the literal to be used in case the numerical value is not defined. Example:
```{r}
st <- star_schema(mrs_age, dm_mrs_age) %>%
  character_dimensions()
```


### Constellation definition

Based on various star schemas, a constellation can be defined in which star schemas share common dimensions. Dimensions with the same name must be shared. It is defined by the following function:

- `constellation()`: Creates a `constellation` object from a list of `star_schema` objects. All dimensions with the same name in the star schemas have to be conformable. Example:
```{r}
ct <- constellation(list(st_mrs_age, st_mrs_cause), name = "mrs")
```



## Cleaning and conforming data

Once star schemas and fact constellations are defined, data cleaning operations can be carried out on dimensions. There are three groups of functions: 

1. One to obtain dimensions of star schemas and constellations.

1. Another to define data cleaning operations over dimensions.

1. One more to apply operations to star schemas or constellations.

### Obtaining dimensions

We can obtain dimensions from a star schema or conformed dimensions from a fact constellation. Available functions in both cases are similar.

#### Star schema

- `get_dimension_names()`: Get the names of the dimensions of a star schema. Role playing dimensions are not considered. Example:
```{r}
dn <- st_mrs_age %>%
  get_dimension_names()
```

- `get_dimension()`: Get a dimension of a star schema given its name. Role dimensions can be obtained but not role playing dimensions. Example:
```{r}
where <- st_mrs_age %>%
  get_dimension("where")
```


#### Constellation

- `get_conformed_dimension_names()`: Get the names of the conformed dimensions of a constellation. Example:
```{r}
dn <- ct_mrs %>%
  get_conformed_dimension_names()
```

- `get_conformed_dimension()`: Get a conformed dimension of a constellation given its name. Example:
```{r}
when <- ct_mrs %>%
  get_conformed_dimension("when")
```


### Definition of updates

Modifications are defined on dimension rows in various ways based exclusively on the values of the dimension fields. Although the surrogate key intervenes in the definition, the result, internally, does not depend on it so that it can be applied more generally in other star schemas.

- `record_update_set()`: A `record_update_set` object is created. Stores updates on dimension records. Each update is made up of a dimension name, an old value set, and a new value set. Example:
```{r}
updates <- record_update_set()
```

- `match_records()`: For a dimension, given the primary key of two records, it adds an update to the set of updates that modifies the combination of values of the rest of attributes of the first record so that they become the same as those of the second. Example:
```{r}
updates <- record_update_set() %>%
  match_records(dimension = where,
                old = 1,
                new = 2)
```

- `update_record()`: For a dimension, given the primary key of one record, it adds an update to the set of updates that modifies the combination of values of the rest of attributes of the selected record so that they become those given. Example:
```{r}
updates <- record_update_set() %>%
  update_record(
    dimension = where,
    old = 1,
    values = c("1", "CT", "Bridgeport")
  )
```

- `update_selection()`: For a dimension, given a vector of column names, a vector of old values and a vector of new values, it adds an update to the set of updates that modifies all the records that have the combination of old values in the columns with the new values in those same columns. Example:
```{r}
updates <- record_update_set() %>%
  update_selection(
    dimension = where,
    columns = c("city"),
    old_values = c("Bridgepor"),
    new_values = c("Bridgeport")
  )
```

- `update_selection_general()`: For a dimension, given a vector of column names, a vector of old values for those columns, another vector column names, and a vector of new values for those columns, it adds an update to the set of updates that modifies all the records that have the combination of old values in the first column vector with the new values in the second column vector. Example:
```{r}
updates <- record_update_set() %>%
  update_selection_general(
    dimension = where,
    columns_old = c("state", "city"),
    old_values = c("CT", "Bridgepor"),
    columns_new = c("city"),
    new_values = c("Bridgeport")
  )
```


### Updates application

Defined updates can be applied on a star schema or on the conformed dimension of a fact constellation.

#### Star schema

- `modify_dimension_records()`: Given a list of dimension record update operations, they are applied on the dimensions of the `star_schema` object. Update operations must be defined with the set of functions available for that purpose. Example:
```{r}
st <- st_mrs_age %>%
  modify_dimension_records(updates_st_mrs_age)
```


#### Constellation

- `modify_conformed_dimension_records()`: Given a list of dimension record update operations, they are applied on the conformed dimensions of the `constellation` object. Update operations must be defined with the set of functions available for that purpose. Example:
```{r}
ct <- ct_mrs %>%
  modify_conformed_dimension_records(updates_st_mrs_age)
```


## Incremental refresh

When new data is obtained, an incremental refresh of the data can be carried out, both of the dimensions and of the facts. Incremental refresh can be applied to both star schema and fact constellation, using the following functions.

#### Star schema

- `incremental_refresh_star_schema()`: Incrementally refresh a star schema with the content of a new one that is integrated into the first. Once the dimensions are integrated, if there are records in the fact table whose keys match the new ones, new ones can be ignored, they can be replaced by new ones, all of them can be grouped using the aggregation functions, or they can be deleted. Therefore, the possible values of the `existing` parameter are: "ignore", "replace", "group" or "delete". Example:
```{r}
st <- st_mrs_age %>%
  incremental_refresh_star_schema(st_mrs_age_w10, existing = "replace")
```


#### Constellation

- `incremental_refresh_constellation()`: Incrementally refresh a star schema in a constellation with the content of a new star schema that is integrated into the first. Example:
```{r}
ct <- ct_mrs %>%
  incremental_refresh_constellation(st_mrs_age_w10, existing = "replace")
```


## Exporting results

Once the data has been properly structured and transformed, it can be exported to be consulted with other tools. Various export formats have been defined, both for star schemas and for constellations, using the following functions.

### Star schema

- `star_schema_as_flat_table()`: We can again obtain a flat table, implemented using a `tibble`, from a star schema. Example:
```{r}
ft <- st_mrs_age %>%
  star_schema_as_flat_table()
```


- `star_schema_as_multistar()`: We can obtain a `multistar`. A `multistar` only distinguishes between general and conformed dimensions, each dimension has its own data. It can contain multiple fact tables. Example:
```{r}
ms <- st_mrs_age %>%
  star_schema_as_multistar()
```


- `star_schema_as_tibble_list()`: We can obtain a `tibble` list with them. Role playing dimensions can be optionally included. Example:
```{r}
tl <- st_mrs_age %>%
  star_schema_as_tibble_list(include_role_playing = TRUE)
```


### Constellation

- `constellation_as_multistar()`: We can obtain a `multistar`. A `multistar` only distinguishes between general and conformed dimensions, each dimension has its own data. It can contain multiple fact tables. Example:
```{r}
ms <- ct_mrs %>%
  constellation_as_multistar()
```


- `constellation_as_tibble_list()`: We can obtain a `tibble` list with them. Role playing dimensions can be optionally included. Example:
```{r}
tl <- ct_mrs %>%
  constellation_as_tibble_list(include_role_playing = TRUE)
```


# Conclusions

`starschemar` package offers a set of operations that allow us to transform flat tables into star schemas. Star schemas support the definition of role playing and role dimensions. Additional transformation operations can be applied to each star schema to adapt the format of the data. From several star schemas you can define fact constellation with conformed dimensions.

Cleaning and conforming data operations can be defined on the star schemas and fact constellation. To update the data, incremental refresh operations are offered, also applicable on said structures. In addition, there are several possibilities to export the results obtained in the form of easily treatable `tibble`-based structures.

Operations have been designed to be intuitive and easy to use. The result greatly facilitates the data transformation process for the exposed situation.



# References
